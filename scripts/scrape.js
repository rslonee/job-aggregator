// scripts/scrape.js

import { getAllSites, upsertJobsForSite } from './lib/db.js'
import { scrapeWorkday, scrapeHTML }      from './lib/scrapers.js'

async function main() {
  try {
    const sites = await getAllSites()

    for (const site of sites) {
      let jobs = []

      if (site.scraper_type === 'workday') {
        // Pass site.base_url (exactly as stored) into your scraper
        jobs = await scrapeWorkday(site.url, site.name, site.base_url)
      } else if (site.scraper_type === 'html') {
        jobs = await scrapeHTML(site.url, site.name, site.base_url)
      }

      console.log(`üîç Debug "${site.name}" scrape returned ${jobs.length} jobs`)
      if (jobs.length) {
        await upsertJobsForSite(site.id, jobs)
        console.log(`‚úÖ Upserted ${jobs.length} jobs from "${site.name}"`)
      } else {
        console.log(`‚Äì No jobs found for "${site.name}"`)
      }
    }

    process.exit(0)
  } catch (error) {
    console.error('üî¥ Error during scraping:', error)
    process.exit(1)
  }
}

main()
